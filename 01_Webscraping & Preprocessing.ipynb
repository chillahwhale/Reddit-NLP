{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Project: Subreddit Binary Text Classification \n",
    "- In this binary classification problem, I scrape data from two subreddits (*r/userexperience* and *r/UXResearch*) using [Pushshiftâ€™s API](https://github.com/pushshift/api), then use Natural Language Processing (NLP) to train for a classifier model on which subreddit a given post came from.\n",
    "- This is the first of two notebooks for this project. In this notebook, I scrape the subreddit data, explore the data, and prepare the dataset that I use for modeling.\n",
    "---\n",
    "\n",
    "# Contents\n",
    "- [Scrape Reddit data with Pushshift API](#Scrape-Reddit-data-with-Pushshift-API)\n",
    "- [EDA and data cleaning](#EDA-and-data-cleaning)\n",
    "- [Prepare merged dataset for modeling](#Prepare-merged-dataset-for-modeling) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the magic trio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# nlp\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Reddit data with Pushshift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pull text from api\n",
    "def pull_text(post_type, subreddit, n_iter):\n",
    "    df_list = []\n",
    "    current_time = 1587495632 # 1PM MST on 4/21/20\n",
    "    for _ in range(n_iter):\n",
    "        url = 'https://api.pushshift.io/reddit/search/'\n",
    "        res = requests.get(url + str(post_type), \n",
    "        params={\n",
    "            'subreddit': subreddit, \n",
    "            'size': 1000,\n",
    "            'before': current_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "        df = pd.DataFrame(res.json()['data'])\n",
    "        if post_type == 'comment':\n",
    "            df = df.loc[:, ['id', 'created_utc', 'author', 'body', 'subreddit']]\n",
    "        if post_type == 'submission':\n",
    "            df = df.loc[:, ['id', 'created_utc', 'author', 'title', 'selftext', 'subreddit']]\n",
    "        df_list.append(df)\n",
    "        current_time = df.created_utc.min()\n",
    "    \n",
    "    return pd.concat(df_list, axis=0)\n",
    "\n",
    "# function adapted from Tim Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw text files as variables\n",
    "ex_comment_raw = pull_text('comment', 'userexperience', 6)  # userexperience comments\n",
    "res_comment_raw = pull_text('comment', 'UXResearch', 6)     # uxreseearch comments\n",
    "ex_subm_raw = pull_text('submission', 'userexperience', 2)  # userexperience submissions\n",
    "res_subm_raw = pull_text('submission', 'UXResearch', 2)     # uxresearch submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp commment shape: (6000, 5)\n",
      "res commment shape: (5105, 5)\n",
      "exp submission shape: (2000, 6)\n",
      "res submission shape: (1492, 6)\n"
     ]
    }
   ],
   "source": [
    "print('exp commment shape:', ex_comment_raw.shape)\n",
    "print('res commment shape:',res_comment_raw.shape)\n",
    "print('exp submission shape:',ex_subm_raw.shape)\n",
    "print('res submission shape:',res_subm_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'created_utc', 'author', 'body', 'subreddit'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_comment_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'created_utc', 'author', 'title', 'selftext', 'subreddit'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_subm_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp commment null: id             0\n",
      "created_utc    0\n",
      "author         0\n",
      "body           0\n",
      "subreddit      0\n",
      "dtype: int64\n",
      "res commment null: id             0\n",
      "created_utc    0\n",
      "author         0\n",
      "body           0\n",
      "subreddit      0\n",
      "dtype: int64\n",
      "exp submission null: id              0\n",
      "created_utc     0\n",
      "author          0\n",
      "title           0\n",
      "selftext       12\n",
      "subreddit       0\n",
      "dtype: int64\n",
      "res submission null: id             0\n",
      "created_utc    0\n",
      "author         0\n",
      "title          0\n",
      "selftext       4\n",
      "subreddit      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check nulls\n",
    "print('exp commment null:', ex_comment_raw.isnull().sum())\n",
    "print('res commment null:',res_comment_raw.isnull().sum())\n",
    "print('exp submission null:',ex_subm_raw.isnull().sum())\n",
    "print('res submission null:',res_subm_raw.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "exp comments [removed]\n",
      "id             40\n",
      "created_utc    40\n",
      "author         40\n",
      "body           40\n",
      "subreddit      40\n",
      "dtype: int64\n",
      "\n",
      "res comments [removed]\n",
      "id             17\n",
      "created_utc    17\n",
      "author         17\n",
      "body           17\n",
      "subreddit      17\n",
      "dtype: int64\n",
      "\n",
      "exp submissions [removed]\n",
      "id             712\n",
      "created_utc    712\n",
      "author         712\n",
      "title          712\n",
      "selftext       712\n",
      "subreddit      712\n",
      "dtype: int64\n",
      "\n",
      "exp submissions [removed]\n",
      "id             196\n",
      "created_utc    196\n",
      "author         196\n",
      "title          196\n",
      "selftext       196\n",
      "subreddit      196\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove documents with '[removed]' (i.e., post deleted)\n",
    "print('\\nexp comments [removed]')\n",
    "print(ex_comment_raw[(ex_comment_raw['body'] == '[removed]')].count())\n",
    "print('\\nres comments [removed]')\n",
    "print(res_comment_raw[(res_comment_raw['body'] == '[removed]')].count())\n",
    "print('\\nexp submissions [removed]')\n",
    "print(ex_subm_raw[(ex_subm_raw['selftext'] == '[removed]')].count())\n",
    "print('\\nexp submissions [removed]')\n",
    "print(res_subm_raw[(res_subm_raw['selftext'] == '[removed]')].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate comments and submissions dataframes\n",
    "comments = pd.concat([ex_comment_raw, res_comment_raw], ignore_index=True)\n",
    "submissions = pd.concat([ex_subm_raw, res_subm_raw], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with [removed]\n",
    "comments = comments.drop(comments[comments.body == '[removed]'].index)\n",
    "submissions = submissions.drop(submissions[submissions.selftext == '[removed]'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for submissions, concatenate 'title' and 'selftext' features\n",
    "# in order to a) get more text data, and; b) make same shape as comments\n",
    "# this will also help to take care of empty selftext without deleting them\n",
    "submissions['text'] = submissions['title'] + str(' ') + submissions['selftext']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare merged dataset for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g5ib1h</td>\n",
       "      <td>1587486153</td>\n",
       "      <td>yellow_brick</td>\n",
       "      <td>userexperience</td>\n",
       "      <td>Webinar en franÃ§ais : Design Sprint Session 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g5ck0j</td>\n",
       "      <td>1587463711</td>\n",
       "      <td>thisisfats</td>\n",
       "      <td>userexperience</td>\n",
       "      <td>I want to create a volunteer directory for peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g5cg9z</td>\n",
       "      <td>1587463161</td>\n",
       "      <td>nix_oxten94</td>\n",
       "      <td>userexperience</td>\n",
       "      <td>Starting a career in UX is a good option for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g534qi</td>\n",
       "      <td>1587422673</td>\n",
       "      <td>Mariciano</td>\n",
       "      <td>userexperience</td>\n",
       "      <td>Best way to analyse web shops and what makes t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>g4pfyy</td>\n",
       "      <td>1587373548</td>\n",
       "      <td>herotohero</td>\n",
       "      <td>userexperience</td>\n",
       "      <td>My company is hosting a virtual conference and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  created_utc        author       subreddit  \\\n",
       "0   g5ib1h   1587486153  yellow_brick  userexperience   \n",
       "3   g5ck0j   1587463711    thisisfats  userexperience   \n",
       "4   g5cg9z   1587463161   nix_oxten94  userexperience   \n",
       "6   g534qi   1587422673     Mariciano  userexperience   \n",
       "10  g4pfyy   1587373548    herotohero  userexperience   \n",
       "\n",
       "                                                 text  \n",
       "0   Webinar en franÃ§ais : Design Sprint Session 1 ...  \n",
       "3   I want to create a volunteer directory for peo...  \n",
       "4   Starting a career in UX is a good option for m...  \n",
       "6   Best way to analyse web shops and what makes t...  \n",
       "10  My company is hosting a virtual conference and...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop 'title' and 'selftext' columns \n",
    "submissions_to_merge = submissions.drop(columns=['title', 'selftext'], axis=1)\n",
    "submissions_to_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g5ib1h</td>\n",
       "      <td>1587486153</td>\n",
       "      <td>yellow_brick</td>\n",
       "      <td>Webinar en franÃ§ais : Design Sprint Session 1 ...</td>\n",
       "      <td>userexperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g5ck0j</td>\n",
       "      <td>1587463711</td>\n",
       "      <td>thisisfats</td>\n",
       "      <td>I want to create a volunteer directory for peo...</td>\n",
       "      <td>userexperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g5cg9z</td>\n",
       "      <td>1587463161</td>\n",
       "      <td>nix_oxten94</td>\n",
       "      <td>Starting a career in UX is a good option for m...</td>\n",
       "      <td>userexperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g534qi</td>\n",
       "      <td>1587422673</td>\n",
       "      <td>Mariciano</td>\n",
       "      <td>Best way to analyse web shops and what makes t...</td>\n",
       "      <td>userexperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>g4pfyy</td>\n",
       "      <td>1587373548</td>\n",
       "      <td>herotohero</td>\n",
       "      <td>My company is hosting a virtual conference and...</td>\n",
       "      <td>userexperience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  created_utc        author  \\\n",
       "0   g5ib1h   1587486153  yellow_brick   \n",
       "3   g5ck0j   1587463711    thisisfats   \n",
       "4   g5cg9z   1587463161   nix_oxten94   \n",
       "6   g534qi   1587422673     Mariciano   \n",
       "10  g4pfyy   1587373548    herotohero   \n",
       "\n",
       "                                                 text       subreddit  \n",
       "0   Webinar en franÃ§ais : Design Sprint Session 1 ...  userexperience  \n",
       "3   I want to create a volunteer directory for peo...  userexperience  \n",
       "4   Starting a career in UX is a good option for m...  userexperience  \n",
       "6   Best way to analyse web shops and what makes t...  userexperience  \n",
       "10  My company is hosting a virtual conference and...  userexperience  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reorder columns to match comments \n",
    "submissions_to_merge = submissions_to_merge[['id', 'created_utc', 'author', 'text', 'subreddit']]\n",
    "submissions_to_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fo3tjjq</td>\n",
       "      <td>1587492704</td>\n",
       "      <td>ryusakai</td>\n",
       "      <td>Sure no problem!</td>\n",
       "      <td>userexperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fo3t2lw</td>\n",
       "      <td>1587492485</td>\n",
       "      <td>_heisenberg__</td>\n",
       "      <td>Sorry I never got back to you here. So I'm of ...</td>\n",
       "      <td>userexperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fo3no3f</td>\n",
       "      <td>1587489935</td>\n",
       "      <td>WisePudding</td>\n",
       "      <td>The ones you might show me if we only had 5 mi...</td>\n",
       "      <td>userexperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fo3njfe</td>\n",
       "      <td>1587489875</td>\n",
       "      <td>Mariciano</td>\n",
       "      <td>I honestly think the same, but what can I do, ...</td>\n",
       "      <td>userexperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fo3g9o4</td>\n",
       "      <td>1587486394</td>\n",
       "      <td>tanaysharma97</td>\n",
       "      <td>Oh, okay! Can you tell me some of the projects...</td>\n",
       "      <td>userexperience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  created_utc         author  \\\n",
       "0  fo3tjjq   1587492704       ryusakai   \n",
       "1  fo3t2lw   1587492485  _heisenberg__   \n",
       "2  fo3no3f   1587489935    WisePudding   \n",
       "3  fo3njfe   1587489875      Mariciano   \n",
       "4  fo3g9o4   1587486394  tanaysharma97   \n",
       "\n",
       "                                                text       subreddit  \n",
       "0                                   Sure no problem!  userexperience  \n",
       "1  Sorry I never got back to you here. So I'm of ...  userexperience  \n",
       "2  The ones you might show me if we only had 5 mi...  userexperience  \n",
       "3  I honestly think the same, but what can I do, ...  userexperience  \n",
       "4  Oh, okay! Can you tell me some of the projects...  userexperience  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename 'body' column to 'text'; same as submissions df\n",
    "comments_to_merge = comments.rename(columns={'body': 'text'})\n",
    "comments_to_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13632, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge submissions and comments dataframes\n",
    "merged = pd.concat([comments_to_merge, submissions_to_merge], ignore_index=True)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "created_utc    0\n",
       "author         0\n",
       "text           0\n",
       "subreddit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('./datasets/merged_unprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters\n",
    "spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
    "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "              \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\", \"\\n\"]\n",
    "for char in spec_chars:\n",
    "    merged['text'] = merged['text'].str.replace(char, ' ')\n",
    "    \n",
    "# and rejoin the whitespaces we created\n",
    "merged['text'] = merged['text'].str.split().str.join(\" \")\n",
    "\n",
    "# https://medium.com/analytics-vidhya/simplify-your-dataset-cleaning-with-pandas-75951b23568e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase-ify\n",
    "merged['text'] = [doc.lower() for doc in merged['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create positive(1) and negative variables\n",
    "merged['subreddit'] = merged['subreddit'].map({'userexperience': 1, 'UXResearch': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out csv for modeling\n",
    "merged.to_csv('./datasets/merged_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
